{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONCRETE LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "5   266.0               114.0      0.0  228.0               0.0   \n",
       "6   380.0                95.0      0.0  228.0               0.0   \n",
       "7   380.0                95.0      0.0  228.0               0.0   \n",
       "8   266.0               114.0      0.0  228.0               0.0   \n",
       "9   475.0                 0.0      0.0  228.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  \n",
       "5             932.0           670.0   90     47.03  \n",
       "6             932.0           594.0  365     43.70  \n",
       "7             932.0           594.0   28     36.45  \n",
       "8             932.0           670.0   28     45.85  \n",
       "9             932.0           594.0   28     39.29  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data=pd.read_csv('concrete_data.csv')\n",
    "concrete_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "predictors_norm.head()\n",
    "\n",
    "target_norm=(target-target.mean())/target.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(predictors_norm,target_norm,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors_norm.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 1s - loss: 1.7132 - val_loss: 1.4108 - 1s/epoch - 80ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.2578 - val_loss: 1.0809 - 75ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.0274 - val_loss: 0.9193 - 74ms/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 0.9210 - val_loss: 0.8312 - 73ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 0.8538 - val_loss: 0.7776 - 79ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 0.8047 - val_loss: 0.7402 - 74ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 0.7647 - val_loss: 0.7090 - 71ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 0.7277 - val_loss: 0.6823 - 74ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 0.6921 - val_loss: 0.6525 - 72ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 0.6633 - val_loss: 0.6282 - 75ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 0.6351 - val_loss: 0.6054 - 71ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 0.6058 - val_loss: 0.5817 - 72ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 0.5815 - val_loss: 0.5583 - 72ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 0.5544 - val_loss: 0.5369 - 70ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 0.5306 - val_loss: 0.5145 - 76ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 0.5079 - val_loss: 0.4963 - 76ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 0.4857 - val_loss: 0.4791 - 81ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 0.4659 - val_loss: 0.4632 - 85ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 0.4491 - val_loss: 0.4470 - 78ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 0.4307 - val_loss: 0.4360 - 72ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 0.4148 - val_loss: 0.4191 - 72ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 0.4009 - val_loss: 0.4128 - 71ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 0.3867 - val_loss: 0.4011 - 73ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 0.3757 - val_loss: 0.3936 - 72ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 0.3646 - val_loss: 0.3848 - 71ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 0.3545 - val_loss: 0.3748 - 70ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 0.3462 - val_loss: 0.3686 - 71ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 0.3377 - val_loss: 0.3582 - 72ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 0.3288 - val_loss: 0.3517 - 71ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 0.3208 - val_loss: 0.3438 - 71ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 0.3129 - val_loss: 0.3351 - 72ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 0.3039 - val_loss: 0.3291 - 71ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 0.2976 - val_loss: 0.3210 - 71ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 0.2880 - val_loss: 0.3137 - 71ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 0.2802 - val_loss: 0.3056 - 71ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 0.2730 - val_loss: 0.2975 - 69ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 0.2648 - val_loss: 0.2874 - 70ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 0.2562 - val_loss: 0.2844 - 72ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 0.2500 - val_loss: 0.2787 - 71ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 0.2454 - val_loss: 0.2727 - 70ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 0.2394 - val_loss: 0.2696 - 73ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 0.2341 - val_loss: 0.2644 - 73ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 0.2282 - val_loss: 0.2628 - 74ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 0.2250 - val_loss: 0.2585 - 70ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 0.2207 - val_loss: 0.2582 - 73ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 0.2172 - val_loss: 0.2504 - 70ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 0.2140 - val_loss: 0.2514 - 71ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 0.2126 - val_loss: 0.2486 - 72ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 0.2103 - val_loss: 0.2428 - 70ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 0.2041 - val_loss: 0.2444 - 71ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 0.2020 - val_loss: 0.2394 - 82ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 0.1996 - val_loss: 0.2346 - 76ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 0.1956 - val_loss: 0.2356 - 71ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 0.1921 - val_loss: 0.2305 - 71ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 0.1909 - val_loss: 0.2275 - 72ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 0.1873 - val_loss: 0.2243 - 71ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 0.1835 - val_loss: 0.2236 - 73ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 0.1806 - val_loss: 0.2195 - 74ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 0.1777 - val_loss: 0.2163 - 72ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 0.1748 - val_loss: 0.2150 - 70ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 0.1723 - val_loss: 0.2127 - 70ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 0.1700 - val_loss: 0.2079 - 71ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 0.1688 - val_loss: 0.2071 - 70ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 0.1657 - val_loss: 0.2067 - 71ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 0.1615 - val_loss: 0.2021 - 72ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 0.1610 - val_loss: 0.2030 - 70ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 0.1581 - val_loss: 0.1977 - 72ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 0.1570 - val_loss: 0.1976 - 71ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 0.1520 - val_loss: 0.1922 - 73ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 0.1503 - val_loss: 0.1888 - 73ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 0.1474 - val_loss: 0.1899 - 69ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 0.1456 - val_loss: 0.1850 - 72ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 0.1446 - val_loss: 0.1841 - 72ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 0.1425 - val_loss: 0.1805 - 73ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 0.1399 - val_loss: 0.1805 - 70ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 0.1395 - val_loss: 0.1786 - 71ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 0.1381 - val_loss: 0.1774 - 71ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 0.1364 - val_loss: 0.1749 - 72ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 0.1353 - val_loss: 0.1767 - 71ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 0.1339 - val_loss: 0.1729 - 70ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 0.1328 - val_loss: 0.1704 - 72ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 0.1324 - val_loss: 0.1711 - 71ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 0.1336 - val_loss: 0.1656 - 71ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 0.1321 - val_loss: 0.1709 - 72ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 0.1305 - val_loss: 0.1661 - 70ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 0.1270 - val_loss: 0.1651 - 72ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 0.1268 - val_loss: 0.1660 - 72ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 0.1261 - val_loss: 0.1631 - 70ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 0.1248 - val_loss: 0.1635 - 71ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 0.1240 - val_loss: 0.1631 - 72ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 0.1240 - val_loss: 0.1608 - 71ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 0.1220 - val_loss: 0.1585 - 71ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 0.1214 - val_loss: 0.1602 - 71ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 0.1203 - val_loss: 0.1577 - 73ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 0.1187 - val_loss: 0.1561 - 71ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 0.1179 - val_loss: 0.1595 - 73ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 0.1177 - val_loss: 0.1562 - 70ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 0.1172 - val_loss: 0.1532 - 70ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 0.1185 - val_loss: 0.1574 - 71ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 0.1178 - val_loss: 0.1512 - 70ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x136c09f00>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(x_train, y_train, validation_split=0.3, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17573262751102448"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
